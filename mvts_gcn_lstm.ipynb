{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mvts_gnn_rnn_3_expt_12.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Considering edge weights before GCNconv"
      ],
      "metadata": {
        "id": "SOHnUNtb8GBZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Q8WGAUGTitas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d3bc110-f7f4-423e-829f-179413ff0ab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch v:  1.10.0+cu111\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print('Torch v: ', torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "id": "kcKG5amSjACX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99dc9f69-e16a-49d9-916c-8abd9e7f7966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 1.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_sparse-0.6.12-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.12\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.3.tar.gz (370 kB)\n",
            "\u001b[K     |████████████████████████████████| 370 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.1.1-py3-none-any.whl (482 kB)\n",
            "\u001b[K     |████████████████████████████████| 482 kB 25.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.7)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 203 kB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.10.0.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.3-py3-none-any.whl size=581968 sha256=058023008b909a117af15e8aff2932a23b00ef31a241427bf1b2935b229b9221\n",
            "  Stored in directory: /root/.cache/pip/wheels/c3/2a/58/87ce0508964d4def1aafb92750c4f3ac77038efd1b9a89dcf5\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, yacs, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.1 rdflib-6.1.1 torch-geometric-2.0.3 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/uy58al2rwf6yn9u/labels_1540_4classes_icmla_21.pck\n",
        "!wget https://www.dropbox.com/s/4bt5ugb9rimbrgx/mvts_1540_icmla_21.pck"
      ],
      "metadata": {
        "id": "li_PYodLjDJ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebc25061-8f04-4194-a366-d02dba123dcc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-09 22:11:48--  https://www.dropbox.com/s/uy58al2rwf6yn9u/labels_1540_4classes_icmla_21.pck\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.18, 2620:100:6020:18::a27d:4012\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/uy58al2rwf6yn9u/labels_1540_4classes_icmla_21.pck [following]\n",
            "--2022-02-09 22:11:48--  https://www.dropbox.com/s/raw/uy58al2rwf6yn9u/labels_1540_4classes_icmla_21.pck\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucc6143a4d22f42b7dfdbb6c608e.dl.dropboxusercontent.com/cd/0/inline/BfZdB5sW_WokazcZQOZGi6v0REpQp5zUicZ_7PgJwSdN55polLh3zzO5C3elautC8tcq5ahTTgaGNKrXh3hD7fmP9X0mccVIJvWd8Wu9gbJeR2AA0SygwUfsV34mNHD-Jrp8uHRWe4Sk5LgdZ-J_mhqW/file# [following]\n",
            "--2022-02-09 22:11:48--  https://ucc6143a4d22f42b7dfdbb6c608e.dl.dropboxusercontent.com/cd/0/inline/BfZdB5sW_WokazcZQOZGi6v0REpQp5zUicZ_7PgJwSdN55polLh3zzO5C3elautC8tcq5ahTTgaGNKrXh3hD7fmP9X0mccVIJvWd8Wu9gbJeR2AA0SygwUfsV34mNHD-Jrp8uHRWe4Sk5LgdZ-J_mhqW/file\n",
            "Resolving ucc6143a4d22f42b7dfdbb6c608e.dl.dropboxusercontent.com (ucc6143a4d22f42b7dfdbb6c608e.dl.dropboxusercontent.com)... 162.125.7.15, 2620:100:6019:15::a27d:40f\n",
            "Connecting to ucc6143a4d22f42b7dfdbb6c608e.dl.dropboxusercontent.com (ucc6143a4d22f42b7dfdbb6c608e.dl.dropboxusercontent.com)|162.125.7.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/plain]\n",
            "Saving to: ‘labels_1540_4classes_icmla_21.pck’\n",
            "\n",
            "labels_1540_4classe     [ <=>                ]  12.19K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-02-09 22:11:49 (303 MB/s) - ‘labels_1540_4classes_icmla_21.pck’ saved [12479]\n",
            "\n",
            "--2022-02-09 22:11:49--  https://www.dropbox.com/s/4bt5ugb9rimbrgx/mvts_1540_icmla_21.pck\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.18, 2620:100:6020:18::a27d:4012\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/4bt5ugb9rimbrgx/mvts_1540_icmla_21.pck [following]\n",
            "--2022-02-09 22:11:49--  https://www.dropbox.com/s/raw/4bt5ugb9rimbrgx/mvts_1540_icmla_21.pck\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc816de207eb45c0cc49e76c45c8.dl.dropboxusercontent.com/cd/0/inline/Bfa8R6XLB1rzBgAf1VtPlSjvrIYCvuoJLAbkbXZswNLRygHcJ0AfyzFjwhjRAY5uUeZG8dLZZ5R28P0jRhVQKjPYpWo-TBzXQmyHBLJfPIv15XhGsPHVDB7nCb01IqDoVCUY-Gu7eJ8zhSlHwvpk5ege/file# [following]\n",
            "--2022-02-09 22:11:49--  https://uc816de207eb45c0cc49e76c45c8.dl.dropboxusercontent.com/cd/0/inline/Bfa8R6XLB1rzBgAf1VtPlSjvrIYCvuoJLAbkbXZswNLRygHcJ0AfyzFjwhjRAY5uUeZG8dLZZ5R28P0jRhVQKjPYpWo-TBzXQmyHBLJfPIv15XhGsPHVDB7nCb01IqDoVCUY-Gu7eJ8zhSlHwvpk5ege/file\n",
            "Resolving uc816de207eb45c0cc49e76c45c8.dl.dropboxusercontent.com (uc816de207eb45c0cc49e76c45c8.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:601f:15::a27d:90f\n",
            "Connecting to uc816de207eb45c0cc49e76c45c8.dl.dropboxusercontent.com (uc816de207eb45c0cc49e76c45c8.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BfZ7iZnl4bDGpJE1ExB32UHL8uXrQK4IFB2FXO3IKHltt5VhzBDUUCIKSLx_YsQsiVxvyw1S8oqCxQt3erlhsKZ9ALy0tIUpVJAhNOAo4YcIYUD_S_3WzdI7lK_zRx4AenbOMk5VJ5a9N-wlzKasPJbhtyvFTJ4bqZvfgXJEhK7k8zuO-IL-RO23QdRzUBtuCeAfnt9EVMItv5RtMLZk-PObEU1fauIMxXF29cXyZjhSGY34bKk9vRPNBECSQnf2P6jxqULJU2-0dyww_ERtpCXc4mE6wm_eGN6HToWjicQpwG8sZ8MlRDogHdXJ0J3qIS5hsOs7KgppSEJnTDD9Y5qPALVm6NN4GfEwQfuPbNGAgiBY_BHrglkMafkP-c3T6Uk/file [following]\n",
            "--2022-02-09 22:11:49--  https://uc816de207eb45c0cc49e76c45c8.dl.dropboxusercontent.com/cd/0/inline2/BfZ7iZnl4bDGpJE1ExB32UHL8uXrQK4IFB2FXO3IKHltt5VhzBDUUCIKSLx_YsQsiVxvyw1S8oqCxQt3erlhsKZ9ALy0tIUpVJAhNOAo4YcIYUD_S_3WzdI7lK_zRx4AenbOMk5VJ5a9N-wlzKasPJbhtyvFTJ4bqZvfgXJEhK7k8zuO-IL-RO23QdRzUBtuCeAfnt9EVMItv5RtMLZk-PObEU1fauIMxXF29cXyZjhSGY34bKk9vRPNBECSQnf2P6jxqULJU2-0dyww_ERtpCXc4mE6wm_eGN6HToWjicQpwG8sZ8MlRDogHdXJ0J3qIS5hsOs7KgppSEJnTDD9Y5qPALVm6NN4GfEwQfuPbNGAgiBY_BHrglkMafkP-c3T6Uk/file\n",
            "Reusing existing connection to uc816de207eb45c0cc49e76c45c8.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/octet-stream]\n",
            "Saving to: ‘mvts_1540_icmla_21.pck’\n",
            "\n",
            "mvts_1540_icmla_21.     [ <=>                ]  23.26M   125MB/s    in 0.2s    \n",
            "\n",
            "2022-02-09 22:11:50 (125 MB/s) - ‘mvts_1540_icmla_21.pck’ saved [24393763]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def load(file_name):\n",
        "    with open(file_name, 'rb') as fp:\n",
        "        obj = pickle.load(fp)\n",
        "    return obj\n",
        "mvts_1540=load(\"mvts_1540_icmla_21.pck\")\n",
        "labels_1540=load(\"labels_1540_4classes_icmla_21.pck\")\n",
        "print(\"MVTS dataset shape: \", mvts_1540.shape)\n",
        "print(\"Labels shape: \", labels_1540.shape)\n",
        "print(\"np.unique(trainLebel): \",np.unique(labels_1540))\n",
        "print(\"Example mvts: \", mvts_1540[56, :, :])"
      ],
      "metadata": {
        "id": "p3bGVKAljlex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b37d5a30-eaaa-46d9-c359-d39e815e57cf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MVTS dataset shape:  (1540, 33, 60)\n",
            "Labels shape:  (1540,)\n",
            "np.unique(trainLebel):  [0 1 2 3]\n",
            "Example mvts:  [[2.53314194e+03 2.53950344e+03 2.55775049e+03 ... 2.18394810e+03\n",
            "  2.17416641e+03 2.15589318e+03]\n",
            " [4.39921029e+10 4.40222930e+10 4.42221412e+10 ... 3.92203291e+10\n",
            "  3.90725159e+10 3.90107524e+10]\n",
            " [8.10092966e+23 8.12413614e+23 8.12540180e+23 ... 6.96375121e+23\n",
            "  6.93076847e+23 6.91178748e+23]\n",
            " ...\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [3.80000000e+02 3.59000000e+02 4.76000000e+02 ... 8.08000000e+02\n",
            "  7.03000000e+02 7.50000000e+02]\n",
            " [5.35330000e-07 4.56010000e-07 4.30590000e-07 ... 3.71110000e-07\n",
            "  4.05080000e-07 4.13080000e-07]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data label conversion to BINARY class\n",
        "def get_binary_labels_from(labels_str):\n",
        "    tdf = pd.DataFrame(labels_str, columns = ['labels'])\n",
        "    data_classes= [0, 1, 2, 3]# = [\"cat\", \"dog\", \"mouse\"]\n",
        "    d = dict(zip(data_classes, [0, 0, 1, 1])) \n",
        "    arr = tdf['labels'].map(d, na_action='ignore')\n",
        "    return arr.to_numpy()\n",
        "\n",
        "#labels_1540 = get_binary_labels_from(labels_1540)"
      ],
      "metadata": {
        "id": "htL8tL7unlkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Stratified train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(mvts_1540, labels_1540, test_size=0.3, random_state=0, stratify=labels_1540)"
      ],
      "metadata": {
        "id": "lIYuClryjrfM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "#Takes 3D array(x,y,z) >> transpose(y,z) >> return (x,z,y)\n",
        "def GetTransposed2D(arrayFrom):\n",
        "    toReturn = []\n",
        "    alen = arrayFrom.shape[0]\n",
        "    for i in range(0, alen):\n",
        "        toReturn.append(arrayFrom[i].T)\n",
        "    \n",
        "    return np.array(toReturn)\n",
        "\n",
        "#Takes 3D array(x,y,z) >> Flatten() >> return (y,z)\n",
        "def Make2D(array3D):\n",
        "    toReturn = []\n",
        "    x = array3D.shape[0]\n",
        "    y = array3D.shape[1]\n",
        "    for i in range(0, x):\n",
        "        for j in range(0, y):\n",
        "            toReturn.append(array3D[i,j])\n",
        "    \n",
        "    return np.array(toReturn)\n",
        "\n",
        "#Transform instance(92400, 33) into(1540x60x33)\n",
        "def Get3D_MVTS_from2D(array2D, windowSize):\n",
        "    arrlen = array2D.shape[0]\n",
        "    mvts = []\n",
        "    for i in range(0, arrlen, windowSize):\n",
        "        mvts.append(array2D[i:i+windowSize])\n",
        "\n",
        "    return np.array(mvts)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#LSTM uses sigmoid and tanh that are sensitive to magnitude so values need to be normalized\n",
        "# normalize the dataset\n",
        "def GetStandardScaler(data2d):\n",
        "    scaler = StandardScaler()\n",
        "    scaler = scaler.fit(data2d)\n",
        "    return scaler\n",
        "    \n",
        "def GetStandardScaledData(data2d):\n",
        "    scaler = StandardScaler()\n",
        "    scaler = scaler.fit(data2d)\n",
        "    #print(scaler.mean_)\n",
        "    data_scaled = scaler.transform(data2d)\n",
        "    return data_scaled\n",
        "\n",
        "def transform_scale_data(data3d, scaler):\n",
        "    print(\"original data shape:\", data3d.shape) \n",
        "    trans = GetTransposed2D(data3d)\n",
        "    print(\"transposed data shape:\", trans.shape)    #(x, 60, 33)\n",
        "    data2d = Make2D(trans)\n",
        "    print(\"2d data shape:\", data2d.shape)    \n",
        "    #  scaler = GetStandardScaler(data2d)\n",
        "    data_scaled = scaler.transform(data2d)\n",
        "    mvts_scalled = Get3D_MVTS_from2D(data_scaled, data3d.shape[2])#,60)\n",
        "    print(\"mvts data shape:\", mvts_scalled.shape)\n",
        "    transBack = GetTransposed2D(mvts_scalled)\n",
        "    print(\"transBack data shape:\", transBack.shape)\n",
        "    return transBack\n",
        "\n",
        "def build_edge_index_tensor(adj):\n",
        "  num_nodes = adj.shape[0]\n",
        "  source_nodes_ids, target_nodes_ids = [], []\n",
        "  for i in range(num_nodes):\n",
        "    for j in range(num_nodes):\n",
        "      if(adj[i,j]==1):\n",
        "        source_nodes_ids.append(i)\n",
        "        target_nodes_ids.append(j)\n",
        "  edge_index = np.row_stack((source_nodes_ids, target_nodes_ids))\n",
        "  edge_index_tensor = torch.from_numpy(edge_index)\n",
        "  return edge_index_tensor\n",
        "\n",
        "def GetGraphAdjMtrx(squareMtx, thresolds, keep_weights=False): #Apply Thresolds to squareMtx\n",
        "    graphs = []\n",
        "    mtxLen = squareMtx.shape[0]\n",
        "    for thr in thresolds:\n",
        "        m = np.zeros((mtxLen,mtxLen))#r = []        \n",
        "        for i in range(0,mtxLen):\n",
        "            for j in range(0,mtxLen):\n",
        "                if i == j:# or squareMtx[i,j] > thr:\n",
        "                    m[i,j] = 1\n",
        "                elif squareMtx[i,j] > thr:\n",
        "                  if keep_weights == True:\n",
        "                    m[i,j] = squareMtx[i,j]\n",
        "                  else:\n",
        "                    m[i,j] = 1\n",
        "        graphs.append(m)#np.array(r))  \n",
        "    return graphs[0]"
      ],
      "metadata": {
        "id": "qoXbnhcYc2oJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#building standard scaler on train data X\n",
        "trans = GetTransposed2D(X_train)\n",
        "data2d = Make2D(trans)\n",
        "scaler = GetStandardScaler(data2d)\n",
        "\n",
        "X_train = transform_scale_data(X_train, scaler)\n",
        "X_test = transform_scale_data(X_test, scaler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THZJ7TNbdKvV",
        "outputId": "96410480-041e-4090-9309-76b842ed28a1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original data shape: (1078, 33, 60)\n",
            "transposed data shape: (1078, 60, 33)\n",
            "2d data shape: (64680, 33)\n",
            "mvts data shape: (1078, 60, 33)\n",
            "transBack data shape: (1078, 33, 60)\n",
            "original data shape: (462, 33, 60)\n",
            "transposed data shape: (462, 60, 33)\n",
            "2d data shape: (27720, 33)\n",
            "mvts data shape: (462, 60, 33)\n",
            "transBack data shape: (462, 33, 60)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "#check\n",
        "print(\"X_train shape: \", X_train.shape)\n",
        "print(\"y_train shape: \", y_train.shape)\n",
        "print(\"X_test shape: \", X_test.shape)\n",
        "print(\"y_test shape: \", y_test.shape)\n",
        "unique_y_train, counts_y_train = np.unique(y_train, return_counts=True)\n",
        "y_train_stats = dict(zip(unique_y_train, counts_y_train))\n",
        "print(\"y_train_counts\")\n",
        "print(y_train_stats)\n",
        "#270/(269+269+270+270) = 0.25\n",
        "unique_y_test, counts_y_test = np.unique(y_test, return_counts=True)\n",
        "y_test_stats = dict(zip(unique_y_test, counts_y_test))\n",
        "print(\"y_test_counts\")\n",
        "print(y_test_stats)\n",
        "#116/(116+116+115+115) = 0.25"
      ],
      "metadata": {
        "id": "A8sgVpKgkRwD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dc72638-d71b-47c8-95d7-4199fd6dfd6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:  (1078, 33, 60)\n",
            "y_train shape:  (1078,)\n",
            "X_test shape:  (462, 33, 60)\n",
            "y_test shape:  (462,)\n",
            "y_train_counts\n",
            "{0: 269, 1: 269, 2: 270, 3: 270}\n",
            "y_test_counts\n",
            "{0: 116, 1: 116, 2: 115, 3: 115}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title graph utils\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def get_adj_mat(c, th=0, keep_weights=True):\n",
        "  #print(\"Creating graph with th: \", th)\n",
        "  n = c.shape[0]\n",
        "  a = np.zeros((n,n))\n",
        "  for i in range(n):\n",
        "    for j in range(n):\n",
        "      #print(\"before:\", c[i,j])\n",
        "      if(c[i,j]>th):\n",
        "        if(keep_weights):\n",
        "          a[i,j] = c[i,j]\n",
        "          a[j,i] = c[j,i]\n",
        "        else:\n",
        "          a[i,j] = 1\n",
        "          a[j,i] = 1\n",
        "      #print(\"after:\", a[i,j])\n",
        "  return a\n",
        "\n",
        "def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
        "    return np.allclose(a, a.T, rtol=rtol, atol=atol)\n",
        "\n",
        "def get_edge_index_weight_tensor(adj):\n",
        "  num_nodes = adj.shape[0]\n",
        "  source_nodes_ids, target_nodes_ids, edge_weights = [], [], []\n",
        "  for i in range(num_nodes):\n",
        "    for j in range(num_nodes):\n",
        "      if(adj[i,j]>0):\n",
        "        source_nodes_ids.append(i)\n",
        "        target_nodes_ids.append(j)\n",
        "        edge_weights.append(adj[i,j])\n",
        "  edge_index = np.row_stack((source_nodes_ids, target_nodes_ids))\n",
        "  edge_index_tensor = torch.from_numpy(edge_index)\n",
        "  edge_weights_np = np.asarray(edge_weights, dtype=np.float32)\n",
        "  edge_weights_tensor = torch.from_numpy(edge_weights_np)\n",
        "  #print(\"Index shape: \",edge_index_tensor.shape)\n",
        "  #print(\"Weight shape: \",edge_weights_tensor.shape)\n",
        "  #print(edge_index_tensor)\n",
        "  #print(edge_weights_tensor)\n",
        "  return edge_index_tensor, edge_weights_tensor\n",
        "\n",
        "def normalize_node_attributes(mvts):\n",
        "  sc = StandardScaler()\n",
        "  mvts_std = sc.fit_transform(mvts)\n",
        "  return mvts_std\n"
      ],
      "metadata": {
        "id": "s8H7kccGljXz",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data crawler in train dataset\n",
        "num_temporal_split = 4\n",
        "th = 0\n",
        "num_train = X_train.shape[0]\n",
        "num_nodes = 25\n",
        "len_st = 15\n",
        "#populating adjacency matrices and node attributes of train events\n",
        "#(1078, 4, 6, 25, 25)\n",
        "train_adjs = np.zeros((num_train, num_temporal_split, num_nodes, num_nodes))\n",
        "train_nats = np.zeros((num_train, num_temporal_split, num_nodes, len_st))\n",
        "for i in range(num_train):\n",
        "  #print('Event: ', i)\n",
        "  mt = X_train[i].T[:,0:25] #consider first 25 solar params\n",
        "  #mt = normalize_node_attributes(mt) ++++++++++++++++++++++++++++++\n",
        "  for j in range(num_temporal_split):\n",
        "    #print('Temporal split: ', j*15, (j+1)*15)\n",
        "    smt = mt[j*15:(j+1)*15,:]#unnormalized\n",
        "    c_smt = np.corrcoef(smt.T)\n",
        "    c_smt[np.isnan(c_smt)]=0\n",
        "    for l in range(num_nodes): #gcnconv will automatically add self loops\n",
        "      c_smt[l,l] = 0\n",
        "    #smt = normalize_node_attributes(smt)\n",
        "    train_nats[i,j,:,:] = smt.T\n",
        "    adj = get_adj_mat(c_smt, th, True) #change from ex 10\n",
        "    #if(i==0 and j==0):\n",
        "      #print('train i, j: ', i, j)\n",
        "      #print(adj)\n",
        "      #print('is symetric: ', check_symmetric(adj))\n",
        "    train_adjs[i,j,:,:]=adj"
      ],
      "metadata": {
        "id": "Qf70DFtZkTvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data crawler in test dataset\n",
        "num_test = X_test.shape[0]\n",
        "#populating adjacency matrices and node attributes of test events\n",
        "#(462, 4, 6, 25, 25)\n",
        "test_adjs = np.zeros((num_test, num_temporal_split, num_nodes, num_nodes))\n",
        "test_nats = np.zeros((num_test, num_temporal_split, num_nodes, len_st))\n",
        "for i in range(num_test):\n",
        "  #print('Test Event: ', i)\n",
        "  mt = X_test[i].T[:,0:25]\n",
        "  #mt = normalize_node_attributes(mt) +++++++++++++++++++++++++++++++++++++++++\n",
        "  for j in range(num_temporal_split):\n",
        "    #print('Temporal split: ', j*15, (j+1)*15)\n",
        "    smt = mt[j*15:(j+1)*15,:]\n",
        "    c_smt = np.corrcoef(smt.T)\n",
        "    c_smt[np.isnan(c_smt)]=0\n",
        "    for l in range(num_nodes): #gcnconv will automatically add self loops\n",
        "      c_smt[l,l] = 0\n",
        "    #smt = normalize_node_attributes(smt)\n",
        "    test_nats[i,j,:,:] = smt.T\n",
        "    adj = get_adj_mat(c_smt, th, True)\n",
        "    #if(i==0 and j==0):\n",
        "      #print('test i, j: ', i, j)\n",
        "      #print(adj)\n",
        "      #print('is symetric: ', check_symmetric(adj))\n",
        "    test_adjs[i,j,:,:]=adj"
      ],
      "metadata": {
        "id": "hUgLc_bfm3qF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_adjs.shape)\n",
        "print(train_nats.shape)\n",
        "print(test_adjs.shape)\n",
        "print(test_nats.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-qyapvOlPA3",
        "outputId": "e1b4cf9f-ace4-4204-c387-8313ee16556d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1078, 4, 25, 25)\n",
            "(1078, 4, 25, 15)\n",
            "(462, 4, 25, 25)\n",
            "(462, 4, 25, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "#MODELS CELL\n",
        "#node_emb_dim = graph_emb_dim = window_emb_dim = 4; sequence_emb_dim = 128; class_emb_dim = 4\n",
        "# (GCN) Node emb -> (mean) Graph emb -> (Flatten, Linear) -> window emb -> (LSTM) -> Temporal sequence emb -> (Linear) Class emb\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "class MVTS_GCN_RNN(torch.nn.Module):\n",
        "  def __init__(self, num_nodes, input_dims, num_temporal_split, device, gcn_hidden_dims, node_emb_dims, graph_emb_dims, window_emb_dims, sequence_emb_dims, num_classes):\n",
        "    super(MVTS_GCN_RNN, self).__init__()\n",
        "    self.num_nodes = num_nodes\n",
        "    self.input_dims = input_dims\n",
        "    self.num_temporal_split = num_temporal_split\n",
        "    self.device = device\n",
        "    self.gcn_hidden_dims = gcn_hidden_dims\n",
        "    self.node_emb_dims = node_emb_dims\n",
        "    self.graph_emb_dims = graph_emb_dims\n",
        "    self.window_emb_dims = window_emb_dims\n",
        "    self.sequence_emb_dims = sequence_emb_dims\n",
        "    self.num_classes = num_classes \n",
        "\n",
        "    self.smt2vector = nn.LSTM(num_nodes, sequence_emb_dims)\n",
        "    self.conv1 = GCNConv(input_dims, gcn_hidden_dims)\n",
        "    self.conv2 = GCNConv(gcn_hidden_dims, node_emb_dims)\n",
        "    #self.mean_pool = global_mean_pool(node_emb_dims, num_nodes)\n",
        "    #self.node2graph = nn.Linear(node_emb_dims, graph_emb_dims)#change from ex 1\n",
        "    self.seqGraph2window = nn.Linear(sequence_emb_dims+graph_emb_dims, window_emb_dims)\n",
        "    self.window2sequence = nn.LSTM(window_emb_dims, sequence_emb_dims) #change from ex 1\n",
        "    self.sequence2class_space = nn.Linear(sequence_emb_dims, num_classes)\n",
        "\n",
        "  def forward(self, adj_mat_array, node_att_array):\n",
        "     #adj_mat_array -> (4,1,25,25), node_att_array -> (4,25,15)\n",
        "     sequence_vectors = torch.zeros((self.num_temporal_split, self.window_emb_dims), device=self.device).double()\n",
        "     for j in range(self.num_temporal_split):\n",
        "       node_att = node_att_array[j,:,:]#25*15\n",
        "       adj_mat = adj_mat_array[j,:,:]\n",
        "       #prepare for GCNConv\n",
        "       edge_index_tensor, edge_weights_tensor = get_edge_index_weight_tensor(adj_mat)\n",
        "       edge_index = edge_index_tensor.to(self.device) \n",
        "       edge_weights = edge_weights_tensor.to(self.device)\n",
        "       node_attributes_tensor = torch.from_numpy(node_att)\n",
        "       x = node_attributes_tensor.to(self.device)#[25,15]\n",
        "       #for debug\n",
        "       #graph_data = Data(x=x, edge_index=edge_index, edge_weight=edge_weights)\n",
        "       #print('Graph data object: ')\n",
        "       #print(graph_data)\n",
        "       #print('Num nodes: ', graph_data.num_nodes)\n",
        "       #print('Num edges: ', graph_data.num_edges)\n",
        "       #print('Num node features: ',graph_data.num_node_features)\n",
        "       #print('Has iso nodes: ',graph_data.has_isolated_nodes())\n",
        "       #print('Has self loops: ',graph_data.has_self_loops())\n",
        "       #print('Is directed: ', graph_data.is_directed())\n",
        "\n",
        "       #lstm on x.t\n",
        "       smvts = torch.t(x)\n",
        "       #print(smvts.shape)\n",
        "       small_seq_out, _ = self.smt2vector(smvts.view(len(smvts), 1, -1))#input:[15, 25] , output: [15, 128]\n",
        "       last_small_seq_out = small_seq_out[len(small_seq_out)-1] #[1,128]\n",
        "       #GCN on the graph\n",
        "       x = self.conv1(x=x, edge_index=edge_index, edge_weight=edge_weights)\n",
        "       x = F.relu(x)\n",
        "       x = F.dropout(x, training=self.training)\n",
        "       x = self.conv2(x=x, edge_index=edge_index, edge_weight=edge_weights) #x -> [25, 4]\n",
        "       x = F.relu(x) #change from ex 10\n",
        "       x = F.dropout(x, training=self.training) #change from ex 10\n",
        "       #node_embs = x\n",
        "       #graph embedding\n",
        "       x = torch.mean(x, dim=0).view(1,-1) #->[1,4]#mean pool \n",
        "       #x = torch.max(x, dim=0).values.view(1,-1) #max pool\n",
        "       #for debug\n",
        "       #print('Manual mean pooling')\n",
        "       #print(x)\n",
        "       #print('Pytorch mean pooling')\n",
        "       #batch_id = torch.tensor([example_id])\n",
        "       #batch = batch_id.repeat(num_nodes).view(num_nodes, 1)\n",
        "       #print(batch.shape)\n",
        "       #print(batch)\n",
        "       #tempX = global_mean_pool(node_embs, batch)\n",
        "       #print(tempX)\n",
        "       #flattened node embeddings\n",
        "       #x = x.view(1,-1) #x -> [1,100]\n",
        "       #graph embedding by linear projection\n",
        "       #x = self.node2graph(x) #x -> [1,16]\n",
        "       #x = F.relu(x)\n",
        "       graph_vector = x\n",
        "       seq_graph_vector = torch.cat((last_small_seq_out, graph_vector), dim=1) #[1, 132]\n",
        "       #print('Graph cat vec: ', graph_cat_vector.shape) #[1,24]\n",
        "       #window embedding by linear projection\n",
        "       window_vector = self.seqGraph2window(seq_graph_vector)#[1,64]\n",
        "       window_vector = F.relu(window_vector)\n",
        "       #print('Window vec: ', window_vector.shape)\n",
        "       sequence_vectors[j,:]=window_vector\n",
        "     #sequence embedding by RNN, linear, and softmax #sequence_vectors -> [4,6]\n",
        "     #print('Seq vectors shape: ', sequence_vectors.shape) -> [4, 64]\n",
        "     seq_out, _ = self.window2sequence(sequence_vectors.view(len(sequence_vectors), 1, -1)) #input: [4, 64] -> seq_out -> [4,128]\n",
        "     last_seq_out = seq_out[len(seq_out)-1] #[1,128]\n",
        "     #last_seq_out = F.dropout(last_seq_out, training=self.training) #change from ex 10_2\n",
        "     class_space = self.sequence2class_space(last_seq_out) #[1,4]\n",
        "     class_scores = F.log_softmax(class_space, dim=1)\n",
        "     return class_scores\n",
        "      "
      ],
      "metadata": {
        "id": "3wegYjKpnfdv",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training\n",
        "torch.manual_seed(0)\n",
        "\n",
        "NUM_NODES = 25\n",
        "INPUT_DIMS = 15\n",
        "NUM_TEMPORAL_SPLIT = 4\n",
        "GCN_HIDDEN_DIMS = 256 #224 #192 #160 #128 #96 #64 #32 #4 #kIPF used 4 hidden dims for karate (34, 154)\n",
        "NODE_EMB_DIMS = 4 # number of classes/can be tuned\n",
        "#Flatten graph emb = 25 * 4 = 100\n",
        "GRAPH_EMB_DIMS = NODE_EMB_DIMS #change from ex 1\n",
        "#Flatten threshold emb = 4*6=24\n",
        "WINDOW_EMB_DIMS = 64 #number of sparsity threshold/can be increased #change from ex 1 #change from ex 10\n",
        "SEQUENCE_EMB_DIMS = 128 #16 #4 #128 #number of timestamps #change from ex 1 #change from ex 10\n",
        "NUM_CLASSES = 4 #2 binary classification\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "model = MVTS_GCN_RNN(NUM_NODES, INPUT_DIMS, NUM_TEMPORAL_SPLIT, device, GCN_HIDDEN_DIMS, NODE_EMB_DIMS, GRAPH_EMB_DIMS, WINDOW_EMB_DIMS, SEQUENCE_EMB_DIMS, NUM_CLASSES).to(device).double()\n",
        "loss_function = nn.NLLLoss()\n",
        "#optimizer = optim.SGD(model.parameters(), lr=0.01) #change from ex 10\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-3)\n",
        "num_epochs = 0 #change from ex 10\n",
        "\n",
        "#Train\n",
        "for epoch in range(num_epochs):\n",
        "  #print('Epoch: ', epoch)\n",
        "  for i in range(num_train):\n",
        "    optimizer.zero_grad()\n",
        "    #print('Event: ', i)\n",
        "    adj_mat_array = train_adjs[i,:,:,:]#(4,25,25)\n",
        "    node_att_array = train_nats[i,:,:,:] #(4,25,15)\n",
        "    class_scores = model(adj_mat_array, node_att_array) \n",
        "    target = [y_train[i]]\n",
        "    target = torch.from_numpy(np.array(target))\n",
        "    target = target.to(device)\n",
        "    loss = loss_function(class_scores, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  if(epoch%5==0):\n",
        "    print (\"epoch n loss:\", epoch, loss)"
      ],
      "metadata": {
        "id": "_MsuzqV_pqhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fuad's addition + modification**"
      ],
      "metadata": {
        "id": "SBpBgD_z8-XH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title RunEpochs get_accuracy trian test acc\n",
        "def RunEpochs(num_epochs = 1, print_loss_interval = 5): \n",
        "  for epoch in range(num_epochs):\n",
        "    for i in range(num_train):#num_train\n",
        "      model.zero_grad()\n",
        "\n",
        "      class_scores = model(train_adjs[i], train_nats[i]) \n",
        "      #target = [y_train[i]]\n",
        "      target = torch.from_numpy(np.array([y_train[i]]))\n",
        "      target = target.to(device)\n",
        "      loss = loss_function(class_scores, target)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    if(epoch % print_loss_interval == 0):\n",
        "      print (\"epoch n loss:\", epoch, loss)\n",
        "\n",
        "#------------------------------train acc\n",
        "def get_train_accuracy():\n",
        "  num_train = X_train.shape[0]\n",
        "  with torch.no_grad():\n",
        "    numCorrect = 0\n",
        "    for i in range(num_train):\n",
        "      train_class_scores = model(train_adjs[i], train_nats[i])\n",
        "      class_prediction = torch.argmax(train_class_scores, dim=-1) \n",
        "  \n",
        "      if(class_prediction == y_train[i]): \n",
        "        numCorrect = numCorrect + 1\n",
        "    return numCorrect/num_train\n",
        "\n",
        "\n",
        "#---------test acc\n",
        "def get_test_accuracy():\n",
        "  num_test = X_test.shape[0]\n",
        "  with torch.no_grad():\n",
        "    numCorrect = 0\n",
        "    for i in range(num_test):\n",
        "      test_class_scores = model(test_adjs[i], test_nats[i]) #(adj_mat_array, node_att_array)\n",
        "      class_prediction = torch.argmax(test_class_scores, dim=-1) \n",
        "      \n",
        "      if(class_prediction == y_test[i]): \n",
        "        numCorrect = numCorrect + 1\n",
        "    return numCorrect/num_test\n",
        "\n",
        "def get_accuracy():\n",
        "  print (\"train_accuracy:\", get_train_accuracy())\n",
        "  print (\"test_accuracy: \", get_test_accuracy())"
      ],
      "metadata": {
        "cellView": "form",
        "id": "B_JrQ62F9L6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, adjusted_rand_score\n",
        "\n",
        "def get_accuracy_report_by_running_epochs(epochs, epoch_interval):\n",
        "  maxAcc=0\n",
        "  max_classification_report_dict=0\n",
        "  max_acc_epoch = 0\n",
        "  num_test = X_test.shape[0]\n",
        "\n",
        "  for epoch in range(epoch_interval, epochs, epoch_interval):\n",
        "    print(\"current epoch: \", epoch)\n",
        "    RunEpochs(num_epochs = epoch_interval, print_loss_interval = 300)\n",
        "    \n",
        "    #get_accuracy()\n",
        "    with torch.no_grad():\n",
        "      numCorrect = 0\n",
        "      predictaedLabel=[]\n",
        "      for i in range(num_test):\n",
        "        test_class_scores = model(test_adjs[i], test_nats[i]) #(adj_mat_array, node_att_array)\n",
        "        class_prediction = torch.argmax(test_class_scores, dim=-1) \n",
        "        predictaedLabel.append(class_prediction)\n",
        "        if(class_prediction == y_test[i]): \n",
        "          numCorrect = numCorrect + 1\n",
        "      acc = numCorrect/num_test\n",
        "      if acc  > maxAcc: #fgdg=round(acc, 2)\n",
        "        maxAcc=acc\n",
        "        max_acc_epoch = epoch\n",
        "        max_classification_report_dict=metrics.classification_report(y_test, predictaedLabel, digits=3,output_dict=True)\n",
        "\n",
        "  return maxAcc, max_acc_epoch, max_classification_report_dict   "
      ],
      "metadata": {
        "id": "Junw72qOScMg",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 70\n",
        "epoch_interval = 3\n",
        "print(\"current epoch: 0\")\n",
        "get_accuracy()\n",
        "for epoch in range(epoch_interval, epochs, epoch_interval):\n",
        "    print(\"current epoch: \", epoch)\n",
        "    RunEpochs(num_epochs = epoch_interval, print_loss_interval = 300)\n",
        "    get_accuracy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W32Y35TcAL3P",
        "outputId": "83931177-7582-45f6-ad78-395731e959b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current epoch: 0\n",
            "train_accuracy: 0.2560296846011132\n",
            "test_accuracy:  0.2532467532467532\n",
            "current epoch:  3\n",
            "epoch n loss: 0 tensor(2.1446, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
            "train_accuracy: 0.6975881261595547\n",
            "test_accuracy:  0.7186147186147186\n",
            "current epoch:  6\n",
            "epoch n loss: 0 tensor(2.0177, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
            "train_accuracy: 0.725417439703154\n",
            "test_accuracy:  0.7467532467532467\n",
            "current epoch:  9\n",
            "epoch n loss: 0 tensor(2.0001, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
            "train_accuracy: 0.7792207792207793\n",
            "test_accuracy:  0.7857142857142857\n",
            "current epoch:  12\n",
            "epoch n loss: 0 tensor(1.9723, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
            "train_accuracy: 0.7968460111317254\n",
            "test_accuracy:  0.7922077922077922\n",
            "current epoch:  15\n",
            "epoch n loss: 0 tensor(1.8647, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
            "train_accuracy: 0.7987012987012987\n",
            "test_accuracy:  0.79004329004329\n",
            "current epoch:  18\n",
            "epoch n loss: 0 tensor(1.7342, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
            "train_accuracy: 0.8089053803339518\n",
            "test_accuracy:  0.7878787878787878\n",
            "current epoch:  21\n",
            "epoch n loss: 0 tensor(1.6280, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
            "train_accuracy: 0.8153988868274582\n",
            "test_accuracy:  0.79004329004329\n",
            "current epoch:  24\n",
            "epoch n loss: 0 tensor(1.5072, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
            "train_accuracy: 0.8163265306122449\n",
            "test_accuracy:  0.7857142857142857\n",
            "current epoch:  27\n",
            "epoch n loss: 0 tensor(1.3757, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
            "train_accuracy: 0.8348794063079777\n",
            "test_accuracy:  0.8051948051948052\n",
            "current epoch:  30\n",
            "epoch n loss: 0 tensor(1.2981, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
            "train_accuracy: 0.8385899814471243\n",
            "test_accuracy:  0.8095238095238095\n",
            "current epoch:  33\n",
            "epoch n loss: 0 tensor(1.1408, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
            "train_accuracy: 0.852504638218924\n",
            "test_accuracy:  0.8095238095238095\n",
            "current epoch:  36\n",
            "epoch n loss: 0 tensor(0.9927, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
            "train_accuracy: 0.862708719851577\n",
            "test_accuracy:  0.8181818181818182\n",
            "current epoch:  39\n",
            "epoch n loss: 0 tensor(0.9058, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
            "train_accuracy: 0.8478664192949907\n",
            "test_accuracy:  0.8181818181818182\n",
            "current epoch:  42\n",
            "epoch n loss: 0 tensor(0.8200, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
            "train_accuracy: 0.87847866419295\n",
            "test_accuracy:  0.8203463203463204\n",
            "current epoch:  45\n",
            "epoch n loss: 0 tensor(0.7356, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
            "train_accuracy: 0.8821892393320965\n",
            "test_accuracy:  0.8354978354978355\n",
            "current epoch:  48\n",
            "epoch n loss: 0 tensor(0.6688, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
            "train_accuracy: 0.8821892393320965\n",
            "test_accuracy:  0.8268398268398268\n",
            "current epoch:  51\n",
            "epoch n loss: 0 tensor(0.6597, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
            "train_accuracy: 0.8812615955473099\n",
            "test_accuracy:  0.8138528138528138\n",
            "current epoch:  54\n",
            "epoch n loss: 0 tensor(0.5313, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
            "train_accuracy: 0.8951762523191095\n",
            "test_accuracy:  0.816017316017316\n",
            "current epoch:  57\n",
            "epoch n loss: 0 tensor(0.4565, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
            "train_accuracy: 0.8979591836734694\n",
            "test_accuracy:  0.8225108225108225\n",
            "current epoch:  60\n",
            "epoch n loss: 0 tensor(0.4888, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
            "train_accuracy: 0.9128014842300557\n",
            "test_accuracy:  0.816017316017316\n",
            "current epoch:  63\n",
            "epoch n loss: 0 tensor(0.4669, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
            "train_accuracy: 0.9072356215213359\n",
            "test_accuracy:  0.8051948051948052\n",
            "current epoch:  66\n",
            "epoch n loss: 0 tensor(0.4894, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
            "train_accuracy: 0.9257884972170687\n",
            "test_accuracy:  0.8268398268398268\n",
            "current epoch:  69\n",
            "epoch n loss: 0 tensor(0.3366, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
            "train_accuracy: 0.9276437847866419\n",
            "test_accuracy:  0.8203463203463204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run only once per experiment(5 differeent random_state of train_test_data_split)\n",
        "classification_report_dict=[]\n",
        "Accuracy=[]"
      ],
      "metadata": {
        "id": "UgZrrABjtvnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run for each random data state\n",
        "maxAcc, max_acc_epoch, max_classification_report_dict = get_accuracy_report_by_running_epochs(epochs = 70 + 1, epoch_interval = 5)\n",
        " \n",
        "classification_report_dict.append(max_classification_report_dict)   \n",
        "Accuracy.append(maxAcc) "
      ],
      "metadata": {
        "id": "cFphaKOWuGfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxAcc, max_acc_epoch, max_classification_report_dict"
      ],
      "metadata": {
        "id": "EubuGdKFu32v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def doClassSpecificCalulcation(Accuracy,trainLebel,classification_report_dict):\n",
        "  print('\\np.mean(Accuracy) :',np.mean(Accuracy))\n",
        "  print('\\np.std(Accuracy) :',np.std(Accuracy))\n",
        "  print('\\n33333333 p.mean np.std(Accuracy) :     ',np.round(np.mean(Accuracy),2),\"+-\",np.round(np.std(Accuracy),2) )\n",
        "  for j in [0, 1, 2, 3]:#np.unique(trainLebel ): #. len(...) np.unique(trainLebel):  [0 1 2 3]\n",
        "    print('\\n\\n\\n\\nclass :',j) \n",
        "    precision=[]\n",
        "    recall=[]\n",
        "    f1_score=[]\n",
        "    for i in range(len(classification_report_dict)):\n",
        "      report=classification_report_dict[i]\n",
        "      #print('classification_report : \\n',report) \n",
        "      temp=report[str(j)]['precision'] \n",
        "      precision.append(temp)\n",
        "\n",
        "      temp=report[str(j)]['recall'] \n",
        "      recall.append(temp)\n",
        "\n",
        "      temp=report[str(j)]['f1-score'] \n",
        "      f1_score.append(temp)\n",
        "\n",
        "    print('\\np.mean(precision) \\t p.mean(recall) \\t p.mean(f1_score) :') \n",
        "\n",
        "\n",
        "    print(np.mean(precision)) \n",
        "    print(np.mean(recall)) \n",
        "    print(np.mean(f1_score))\n",
        "\n",
        "    print('\\np.mean p.std(precision) \\tp.mean  p.std(recall) \\tp.mean  p.std(f1_score) :')\n",
        "\n",
        "    print(np.round(np.mean(precision),2),\"+-\",np.round(np.std(precision),2) )\n",
        "    print(np.round(np.mean(recall),2),\"+-\",np.round(np.std(recall),2) )\n",
        "    print(np.round(np.mean(f1_score),2),\"+-\",np.round(np.std(f1_score),2) )"
      ],
      "metadata": {
        "id": "XWDbFa3033Hx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "rs0={'0': {'f1-score': 0.9469387755102041,\n",
        "   'precision': 0.8992248062015504,\n",
        "   'recall': 1.0,\n",
        "   'support': 116},\n",
        "  '1': {'f1-score': 0.7981651376146788,\n",
        "   'precision': 0.8529411764705882,\n",
        "   'recall': 0.75,\n",
        "   'support': 116},\n",
        "  '2': {'f1-score': 0.7196652719665273,\n",
        "   'precision': 0.6935483870967742,\n",
        "   'recall': 0.7478260869565218,\n",
        "   'support': 115},\n",
        "  '3': {'f1-score': 0.8288288288288289,\n",
        "   'precision': 0.8598130841121495,\n",
        "   'recall': 0.8,\n",
        "   'support': 115},\n",
        "  'accuracy': 0.8246753246753247,\n",
        "  'macro avg': {'f1-score': 0.8233995034800597,\n",
        "   'precision': 0.8263818634702657,\n",
        "   'recall': 0.8244565217391304,\n",
        "   'support': 462},\n",
        "  'weighted avg': {'f1-score': 0.8236122846622347,\n",
        "   'precision': 0.826597019867953,\n",
        "   'recall': 0.8246753246753247,\n",
        "   'support': 462}}\n",
        "\n",
        "rs1 = {'0': {'f1-score': 0.9316239316239315,\n",
        "   'precision': 0.923728813559322,\n",
        "   'recall': 0.9396551724137931,\n",
        "   'support': 116},\n",
        "  '1': {'f1-score': 0.7905138339920948,\n",
        "   'precision': 0.7299270072992701,\n",
        "   'recall': 0.8620689655172413,\n",
        "   'support': 116},\n",
        "  '2': {'f1-score': 0.6788990825688073,\n",
        "   'precision': 0.7184466019417476,\n",
        "   'recall': 0.6434782608695652,\n",
        "   'support': 115},\n",
        "  '3': {'f1-score': 0.8036529680365295,\n",
        "   'precision': 0.8461538461538461,\n",
        "   'recall': 0.7652173913043478,\n",
        "   'support': 115},\n",
        "  'accuracy': 0.803030303030303,\n",
        "  'macro avg': {'f1-score': 0.8011724540553409,\n",
        "   'precision': 0.8045640672385465,\n",
        "   'recall': 0.8026049475262369,\n",
        "   'support': 462},\n",
        "  'weighted avg': {'f1-score': 0.801431745954703,\n",
        "   'precision': 0.8046604475120994,\n",
        "   'recall': 0.803030303030303,\n",
        "   'support': 462}}\n",
        "rs2 = {'0': {'f1-score': 0.9626556016597512,\n",
        "   'precision': 0.928,\n",
        "   'recall': 1.0,\n",
        "   'support': 116},\n",
        "  '1': {'f1-score': 0.7705627705627706,\n",
        "   'precision': 0.7739130434782608,\n",
        "   'recall': 0.7672413793103449,\n",
        "   'support': 116},\n",
        "  '2': {'f1-score': 0.625,\n",
        "   'precision': 0.6422018348623854,\n",
        "   'recall': 0.6086956521739131,\n",
        "   'support': 115},\n",
        "  '3': {'f1-score': 0.7894736842105263,\n",
        "   'precision': 0.7964601769911505,\n",
        "   'recall': 0.782608695652174,\n",
        "   'support': 115},\n",
        "  'accuracy': 0.79004329004329,\n",
        "  'macro avg': {'f1-score': 0.7869230141082619,\n",
        "   'precision': 0.7851437638329491,\n",
        "   'recall': 0.7896364317841079,\n",
        "   'support': 462},\n",
        "  'weighted avg': {'f1-score': 0.7872679758918248,\n",
        "   'precision': 0.7854286675468288,\n",
        "   'recall': 0.79004329004329,\n",
        "   'support': 462}}\n",
        "rs3 = {'0': {'f1-score': 0.9707112970711297,\n",
        "   'precision': 0.943089430894309,\n",
        "   'recall': 1.0,\n",
        "   'support': 116},\n",
        "  '1': {'f1-score': 0.8584070796460177,\n",
        "   'precision': 0.8738738738738738,\n",
        "   'recall': 0.8434782608695652,\n",
        "   'support': 115},\n",
        "  '2': {'f1-score': 0.6952789699570816,\n",
        "   'precision': 0.6923076923076923,\n",
        "   'recall': 0.6982758620689655,\n",
        "   'support': 116},\n",
        "  '3': {'f1-score': 0.7876106194690266,\n",
        "   'precision': 0.8018018018018018,\n",
        "   'recall': 0.7739130434782608,\n",
        "   'support': 115},\n",
        "  'accuracy': 0.829004329004329,\n",
        "  'macro avg': {'f1-score': 0.828001991535814,\n",
        "   'precision': 0.8277681997194193,\n",
        "   'recall': 0.8289167916041978,\n",
        "   'support': 462},\n",
        "  'weighted avg': {'f1-score': 0.8280236068690533,\n",
        "   'precision': 0.8277246082124131,\n",
        "   'recall': 0.829004329004329,\n",
        "   'support': 462}}\n",
        "rs4 = {'0': {'f1-score': 0.9661016949152543,\n",
        "   'precision': 0.9421487603305785,\n",
        "   'recall': 0.991304347826087,\n",
        "   'support': 115},\n",
        "  '1': {'f1-score': 0.8225806451612903,\n",
        "   'precision': 0.7669172932330827,\n",
        "   'recall': 0.8869565217391304,\n",
        "   'support': 115},\n",
        "  '2': {'f1-score': 0.6425339366515838,\n",
        "   'precision': 0.6761904761904762,\n",
        "   'recall': 0.6120689655172413,\n",
        "   'support': 116},\n",
        "  '3': {'f1-score': 0.776255707762557,\n",
        "   'precision': 0.8252427184466019,\n",
        "   'recall': 0.7327586206896551,\n",
        "   'support': 116},\n",
        "  'accuracy': 0.8051948051948052,\n",
        "  'macro avg': {'f1-score': 0.8018679961226713,\n",
        "   'precision': 0.8026248120501849,\n",
        "   'recall': 0.8057721139430285,\n",
        "   'support': 462},\n",
        "  'weighted avg': {'f1-score': 0.8014676793524739,\n",
        "   'precision': 0.8024001011639006,\n",
        "   'recall': 0.8051948051948052,\n",
        "   'support': 462}}\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Hb6MsIXvQ2CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_reports = []\n",
        "saved_reports.append(rs0)\n",
        "saved_reports.append(rs1)\n",
        "saved_reports.append(rs2)\n",
        "saved_reports.append(rs3)\n",
        "saved_reports.append(rs4)\n",
        "#classification_report_dict.append(rs0)\n",
        "savedAcc = [0.82467, 0.80303, 0.79004, 0.82900, 0.80519]\n",
        "doClassSpecificCalulcation(savedAcc, X_train, saved_reports)"
      ],
      "metadata": {
        "id": "JVLMxEozRH9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(classification_report_dict)"
      ],
      "metadata": {
        "id": "xtqevqEvQ_9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "doClassSpecificCalulcation(Accuracy, X_train, classification_report_dict)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "uObw-OH3LUDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "t-SNE"
      ],
      "metadata": {
        "id": "Iml2QzLqaP-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patheffects as PathEffects\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Utility function to visualize the outputs of PCA and t-SNE\n",
        "\n",
        "def fashion_scatter(x, colors):\n",
        "    # choose a color palette with seaborn.\n",
        "    num_classes = len(np.unique(colors))\n",
        "    palette = np.array(sns.color_palette(\"hls\", num_classes))\n",
        "\n",
        "    # create a scatter plot.\n",
        "    f = plt.figure(figsize=(14, 14))\n",
        "    ax = plt.subplot(aspect='equal')\n",
        "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40, c=palette[colors.astype(np.int)])\n",
        "    plt.xlim(-25, 25)\n",
        "    plt.ylim(-25, 25)\n",
        "    ax.axis('off')\n",
        "    ax.axis('tight')\n",
        "\n",
        "    # add the labels for each digit corresponding to the label\n",
        "    txts = []\n",
        "    lbls = [\"X\", \"M\", \"BC\", \"Q\"]\n",
        "    for i in range(num_classes):\n",
        "\n",
        "        # Position of each label at median of data points.\n",
        "\n",
        "        xtext, ytext = np.median(x[colors == i, :], axis=0)\n",
        "        txt = ax.text(xtext, ytext, lbls[i], fontsize=24)\n",
        "        txt.set_path_effects([\n",
        "            PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
        "            PathEffects.Normal()])\n",
        "        txts.append(txt)\n",
        "\n",
        "    return f, ax, sc, txts"
      ],
      "metadata": {
        "id": "VtRqgQDJaPfr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "from sklearn.manifold import TSNE\n",
        "from numpy import save\n",
        "\n",
        "# save to npy file\n",
        "#save('train_tsne_data.npy', train_tsne)\n",
        "\n",
        "# to load data\n",
        "#numpy.load(\"file path/train_tsne_data.npy\")\n",
        "\n",
        "#train_tsne = load data here #TSNE(random_state=0).fit_transform(train_softs) \n",
        "# train_tsne data already saved in the file, need to load in this variable\n",
        "\n",
        "fashion_scatter(train_tsne, y_train)"
      ],
      "metadata": {
        "id": "MPSjNJ9yam95",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "xe1 = train_tsne[:,0]\n",
        "xe2 = train_tsne[:,1]\n",
        "y = y_train\n",
        "\n",
        "df = pd.DataFrame({'t-SNE dimension 1':xe1, 't-SNE dimension 2':xe2, 'Class':y})\n",
        "df = df.sort_values(by=['Class'], ascending=True)\n",
        "#print(df.iloc[0:25])"
      ],
      "metadata": {
        "id": "E3YIwqH27N6Q",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "legend_map = {0: 'X',\n",
        "              1: 'M',\n",
        "              2: 'BC',\n",
        "              3: 'Q'}\n",
        "fig = plt.figure(figsize=(11, 11))\n",
        "sns.set(font_scale=2)\n",
        "ax = sns.scatterplot(df['t-SNE dimension 1'], df['t-SNE dimension 2'], hue=df['Class'].map(legend_map), \n",
        "                     palette=['red', 'orange', 'blue', 'green'], legend='full')\n",
        "plt.show()\n",
        "img_file = 'all_tsne.pdf'\n",
        "fig.savefig(img_file, dpi=fig.dpi)"
      ],
      "metadata": {
        "id": "tA7jeXeA7Wkg",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ROCKET**"
      ],
      "metadata": {
        "id": "lsLwshAbx32B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    mvts_1540, labels_1540, test_size=0.3, random_state=0, stratify=labels_1540)"
      ],
      "metadata": {
        "id": "ZspOIk8yyD5B"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "#from sklearn.pipeline import make_pipeline\n",
        "\n",
        "#!pip install 'sktime[all_extras]'\n",
        "#!pip install --upgrade numba \n",
        "#-----> ROCKET compiles (via Numba) on import, which may take a few seconds.\n",
        "from sktime.transformations.panel.rocket import Rocket"
      ],
      "metadata": {
        "id": "-eb06MrAkcL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rocket = Rocket()\n",
        "rocket.fit(X_train)\n",
        "X_train_transform = rocket.transform(X_train)\n",
        "\n",
        "classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
        "classifier.fit(X_train_transform, y_train)\n",
        "\n",
        "X_test_transform = rocket.transform(X_test)\n",
        "\n",
        "classifier.score(X_test_transform, y_test)"
      ],
      "metadata": {
        "id": "DLF3K7pbkcRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "J4SrJWbXkcWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fBKJxLgBkcbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZTfG-BrWkcf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "P7l9_keLkckm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VovLU60AkcpS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}